---
id: blog-q4-2025-roundup
slug: q4-2025-roundup
date: 2025-12-18
title: "Quarter 4 2025: Major Platform Updates"
summary: "Three months of updates: 15+ new models, team management, referral program, tiered pricing, data retention, new providers, and much more."
categories: ["Announcements"]
image:
  src: "/blog/q4-2025.png"
  alt: "Q4 2025 Feature Roundup"
  width: 2282
  height: 1198
---

Here's everything new in LLM Gateway over the past three months â€” from cutting-edge models to powerful platform features.

## ğŸ¤– New Models

![New models](/blog/updates/new-models.png)

[Explore models](/models)

## ğŸ‘¥ Team Management

Full **team collaboration** is now available:

- **Roles**: Owner, Admin, and Developer with granular permissions
- **Seat-based pricing**: 3 included seats, additional seats at $10/seat/month
- **Prorated billing**: Fair charges based on your billing cycle
- **Enterprise options**: SSO/SAML, SCIM provisioning, audit logs for larger teams

[Learn more](/changelog/team-members-roles-and-seats) | [Enterprise](/enterprise)

## ğŸ¢ Admin Dashboard

New internal **admin dashboard** for platform management with:

- Token metrics calculation and aggregation
- User and organization management
- Performance monitoring

## ğŸ’° Referral Program

**Earn 1% of every referral's spending** â€” forever!

- Automatic tracking via referral links and cookies
- Earnings credited to your account
- No cap on earnings

Find your referral link in **Settings â†’ Referrals**.

[Learn more here](/referrals)

## ğŸ›¡ï¸ Routing Improvements

![Routing Improvements](/blog/updates/routing.png)

- **Uptime-aware routing** â€” Automatically routes away from low-uptime providers
- **X-No-Fallback header** â€” Prevent automatic provider fallback when needed
- **Provider metrics** â€” Routing decisions include provider performance data
- **Multi-API key support** â€” Load balance across multiple provider keys
- **Latency optimization** â€” Only consider latency when streaming is enabled

[Learn more](https://docs.llmapi.ai/features/routing)

## ğŸ“Š Tiered Pricing

**Volume-based pricing** is now available:

- The more you use, the more you save
- Tiered cache pricing for supported models
- Discounts calculated automatically based on usage
- View pricing tiers on any model's detail page

## ğŸ”’ Data Retention & Storage

![Data Retention](/blog/updates/data-retention.png)

New **data retention controls** with billing:

- **Metadata-only** (default): Only request metadata is stored
- **Full retention**: Store complete request and response data
- **Data storage billing**: Pay only for what you store
- **Data limits**: Set maximum storage limits per organization

Configure in **Settings â†’ Organization â†’ Data Retention**.

## ğŸ” Model Discovery

### Global Model Search

**Search bar in the top navigation** â€” instantly find any model across all providers.

### Model Timeline & Metadata

- **Release dates** (`releasedAt`, `publishedAt`) for all models
- **Model descriptions** on detail pages
- **Visual indicators** for free models and provider mappings
- **Filtered counts** showing matching models and providers

[Explore timeline](/timeline)

## âš–ï¸ Model Comparison

Compare models side-by-side with our new **comparison page**:

- **Input/output token pricing** â€” Compare costs across providers
- **Feature comparison** â€” See capabilities like streaming, vision, tools at a glance
- **Context windows** â€” Compare model limits instantly

[Compare models](/models/compare)

## ğŸ® Playground Enhancements

![Playground](/blog/updates/playground.png)

- **Comparison mode** â€” Compare responses from multiple models side-by-side
- **Group chat** â€” Chat with multiple models simultaneously
- **GitHub MCP tools** â€” Integrated GitHub operations via Model Context Protocol
- **Redirect after signin** â€” Return to your original URL after authentication
- **Image configuration** â€” Set image parameters and reasoning effort options

[Try out Chat Playground](https://chat.llmapi.ai)

## ğŸ“ˆ Analytics & Metrics

![New dashboard](/blog/updates/new-dashboard.png)

- **Cost breakdown** â€” Detailed breakdown in usage API responses
- **Discount savings visualization** â€” See savings on dashboard
- **Throughput metrics** â€” Monitor tokens per second
- **Provider tracking** â€” Track which providers serve requests
- **Real-time metrics** â€” Current minute history calculation
- **Reasoning tokens** â€” Included in cost calculations

[Learn more](https://docs.llmapi.ai/features/cost-breakdown)

## ğŸ’³ Billing Enhancements

![Billing](/blog/updates/billing.png)

- **PDF invoices** â€” Automatically generated and emailed for subscriptions and credits
- **Company address** on invoices
- **Billing email management** â€” Set separate billing contact
- **Top-up credits button** â€” Quick access to add credits
- **Refund tracking** â€” Full visibility in transaction history
- **First-time bonus** â€” Bonus credits on first purchase

## ğŸ” Security Enhancements

- **Email verification required** â€” New accounts must verify before API access
- **Enhanced email validation** â€” Blocks plus signs, disposable emails, blacklisted domains
- **Masked provider keys** â€” Tokens masked in API responses
- **Content filter detection** â€” Proper error handling for filtered content

## ğŸ’¸ Discounts

- **20% off all Google models** â€” Applied automatically
- **10% off all Z.ai models** â€” Applied automatically
- **75% off CanopyWave models** â€” Qwen3-Coder, MiniMax M2, GLM-4.6, Kimi K2 Thinking
- **90% off DeepSeek V3.1** via CanopyWave partnership

[View discounted models](/models?discounted=true)

## ğŸŒ New Provider Support

We've added support for major cloud providers and new partners:

- **AWS Bedrock** â€” Access Llama and other models via Amazon's managed service
- **Microsoft Azure** â€” Native Azure OpenAI integration
- **Google Vertex AI** â€” Full Vertex AI support with global routing
- **CanopyWave** â€” Discounted access to DeepSeek, Kimi, and more
- **NanoGPT** â€” New provider option

[Browse all providers](/providers)

## ğŸ“± API Enhancements

- **Effort parameter** â€” Control reasoning depth for Claude Opus 4.5
- **no_reasoning flag** â€” Disable reasoning when not needed
- **Responses API** â€” Support for GPT-5 Pro and GPT-5.1 Codex
- **Thought signatures** â€” Included in Google tool calls
- **Custom upload limits** â€” Configure per-gateway limits
- **Unsupported message handling** â€” Clear feedback for unsupported features
- **JSON schema response format** â€” Structured output with `json_schema` response format
- **JSON Output filter** â€” Filter models by JSON output support in UI
- **OpenAI JSON schema conversion** â€” Automatic format conversion for Google models
- **DeepSeek JSON schema** â€” Native JSON schema output support for DeepSeek V3.1

## ğŸ“š Documentation

- **Cline integration guide** â€” Use LLM Gateway with Cline
- **Cursor guide** â€” IDE integration documentation
- **Data retention & caching docs** â€” Full documentation
- **Reasoning docs** â€” Guidelines for reasoning models
- **Collapsible links** â€” Improved navigation
- **GitHub timestamps** â€” Last edit dates on all pages

[Visit our Docs](https://docs.llmapi.ai)

## ğŸ“§ Email & Notifications

- **Transactional emails** â€” Trial start and cancellation notifications
- **PDF invoice emails** â€” Automatic invoice delivery
- **Onboarding status** â€” Synced with Brevo for marketing

## ğŸ‰ Other Improvements

- **Organization name editing** â€” Update org name in preferences
- **Free model rate limits** â€” Tiered rate limiting for free models
- **Sensitive word check** â€” Parameter support for Z.ai
- **Decimal.js** â€” Precise cost calculations
- **Shared UI package** â€” Reusable components across apps

## ğŸ“¢ Pro Plan Pricing Update

Starting **December 19th, 2025**, Pro plan fees will increase from **0% to 1%**. This remains **80% less** than the 5% fee on the Free plan, ensuring you continue to get exceptional value as you scale.

---

**[Explore all models](/models)** | **[Try the Playground](https://chat.llmapi.ai)** | **[Get started now](/signup)** ğŸš€
