---
title: LangSmith Integration
description: Connect LangSmith to LLM API for AI-powered capabilities
icon: LangSmith
---

import { Step, Steps } from "fumadocs-ui/components/steps";
import { Callout } from "fumadocs-ui/components/callout";

LangSmith is LangChain's platform for tracing, evaluating, and monitoring LLM applications. It helps developers debug AI chains, run evaluations against datasets, and track performance metrics --- all while supporting custom model providers.

LangSmith works alongside LangChain, which supports OpenAI-compatible endpoints. By configuring LLM API in your LangChain application, LangSmith will automatically trace all interactions.

## Prerequisites

- An LLM API account with an API key
- LangSmith installed or accessible

## Setup

<Steps>
<Step>
### Get Your LLM API Key

1. Log in to your [LLM API dashboard](https://app.llmapi.ai/api-keys)
2. Click **Create Key to Start**
3. Copy your new API key immediately â€” it will only be shown once
4. Store the key securely (e.g., in a password manager or `.env` file)

<Callout type="info">
	LLM API is an OpenAI-compatible gateway that gives you access to dozens of AI
	models through a single API key and endpoint.
</Callout>

</Step>

<Step>
### Use LLM API with LangChain and LangSmith

1. Install LangChain and configure LangSmith tracing:

```bash
pip install langchain-openai langsmith
export LANGSMITH_API_KEY="your-langsmith-api-key"
export LANGSMITH_TRACING=true
```

2. Configure LLM API as the model provider in your LangChain code:

```python
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(
model="openai/gpt-4o",
api_key="your-llm-api-key-here",
base_url="https://api.llmapi.ai/v1"
)
response = llm.invoke("Hello!")
```

3. All LLM API requests will now appear in your LangSmith dashboard for tracing and evaluation.

</Step>

<Step>
### Test the Integration

Verify that LangSmith can successfully communicate with LLM API by sending a test request. All requests will now be routed through LLM API.

</Step>
</Steps>

<Callout type="info">
	LangSmith captures every request and response from LLM API, giving you full
	observability over your AI application's behavior.
</Callout>

## Benefits of Using LLM API with LangSmith

- **Multi-Provider Access**: Use models from OpenAI, Anthropic, Google, and more through a single API
- **Cost Control**: Track and limit your AI spending with detailed usage analytics
- **Unified Billing**: One account for all providers instead of managing multiple API keys
- **Caching**: Reduce costs with response caching for repeated requests

<Callout type="info">
	View all available models on the [models page](https://llmapi.ai/models).
</Callout>
