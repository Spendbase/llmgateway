---
title: Jan Integration
description: Connect Jan to LLM API for AI-powered capabilities
icon: Jan
---

import { Step, Steps } from "fumadocs-ui/components/steps";
import { Callout } from "fumadocs-ui/components/callout";

Jan is an open-source desktop application that provides a ChatGPT-like interface for running AI models locally and connecting to remote APIs. It includes a built-in OpenAI-compatible API server and supports both local models (via llama.cpp) and cloud providers.

Jan supports remote OpenAI-compatible endpoints in addition to local models, letting you connect LLM API as a remote provider.

## Prerequisites

- An LLM API account with an API key
- Jan installed or accessible

## Setup

<Steps>
<Step>
### Get Your LLM API Key

1. Log in to your [LLM API dashboard](https://app.llmapi.ai/api-keys)
2. Click **Create Key to Start**
3. Copy your new API key immediately â€” it will only be shown once
4. Store the key securely (e.g., in a password manager or `.env` file)

<Callout type="info">
	LLM API is an OpenAI-compatible gateway that gives you access to dozens of AI
	models through a single API key and endpoint.
</Callout>

</Step>

<Step>
### Configure LLM API in Jan

1. Open Jan on your desktop.
2. Navigate to Settings (gear icon).
3. Under "Remote API" or "OpenAI" section, click to configure a remote provider.
4. Enter the following details:
   - **API Key**: paste the key you copied from app.llmapi.ai/api-keys
   - **Base URL**: https://api.llmapi.ai/v1
5. Enter or select the model ID you wish to use (e.g., openai/gpt-4o).
6. Click "Save" to store the configuration.
7. Select the remote model in the chat panel and start chatting through LLM API.

</Step>

<Step>
### Test the Integration

Verify that Jan can successfully communicate with LLM API by sending a test request. All requests will now be routed through LLM API.

</Step>
</Steps>

<Callout type="info">
	Jan lets you switch between local models and LLM API cloud models at any time,
	giving you the best of both worlds.
</Callout>

## Benefits of Using LLM API with Jan

- **Multi-Provider Access**: Use models from OpenAI, Anthropic, Google, and more through a single API
- **Cost Control**: Track and limit your AI spending with detailed usage analytics
- **Unified Billing**: One account for all providers instead of managing multiple API keys
- **Caching**: Reduce costs with response caching for repeated requests

<Callout type="info">
	View all available models on the [models page](https://llmapi.ai/models).
</Callout>
