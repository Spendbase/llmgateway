---
title: BoltAI Integration
description: Connect BoltAI to LLM API for AI-powered capabilities
icon: BoltAI
---

import { Step, Steps } from "fumadocs-ui/components/steps";
import { Callout } from "fumadocs-ui/components/callout";

BoltAI is a native macOS AI assistant that provides quick access to ChatGPT, Claude, Gemini, and other AI models from your Mac's menu bar. It supports bring-your-own-API-key setups and OpenAI-compatible custom providers for maximum flexibility.

BoltAI supports custom OpenAI-compatible providers, making it easy to connect LLM API for model access.

## Prerequisites

- An LLM API account with an API key
- BoltAI installed or accessible

## Setup

<Steps>
<Step>
### Get Your LLM API Key

1. Log in to your [LLM API dashboard](https://app.llmapi.ai/api-keys)
2. Click **Create Key to Start**
3. Copy your new API key immediately — it will only be shown once
4. Store the key securely (e.g., in a password manager or `.env` file)

<Callout type="info">
	LLM API is an OpenAI-compatible gateway that gives you access to dozens of AI
	models through a single API key and endpoint.
</Callout>

</Step>

<Step>
### Configure LLM API in BoltAI

1. Open BoltAI from your Mac menu bar.
2. Navigate to Preferences → Providers.
3. Click "+" to add a new provider and select "OpenAI Compatible".
4. Enter the following details:
   - **Name**: LLM API
   - **API Key**: paste the key you copied from app.llmapi.ai/api-keys
   - **Base URL**: https://api.llmapi.ai/v1
5. Add the model IDs you want to use (e.g., openai/gpt-4o).
6. Click "Save" to apply.
7. Select LLM API models from the model dropdown when chatting.

</Step>

<Step>
### Test the Integration

Verify that BoltAI can successfully communicate with LLM API by sending a test request. All requests will now be routed through LLM API.

</Step>
</Steps>

<Callout type="info">
	BoltAI's menu bar integration gives you instant access to LLM API models from
	anywhere on your Mac.
</Callout>

## Benefits of Using LLM API with BoltAI

- **Multi-Provider Access**: Use models from OpenAI, Anthropic, Google, and more through a single API
- **Cost Control**: Track and limit your AI spending with detailed usage analytics
- **Unified Billing**: One account for all providers instead of managing multiple API keys
- **Caching**: Reduce costs with response caching for repeated requests

<Callout type="info">
	View all available models on the [models page](https://llmapi.ai/models).
</Callout>
