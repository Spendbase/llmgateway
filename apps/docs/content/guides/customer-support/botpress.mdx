---
title: Botpress Integration
description: Connect Botpress to LLM API for AI-powered capabilities
icon: Botpress
---

import { Step, Steps } from "fumadocs-ui/components/steps";
import { Callout } from "fumadocs-ui/components/callout";

Botpress is an open-source chatbot building platform that uses AI for natural language understanding, conversation management, and knowledge base integration. It powers customer support bots, internal assistants, and interactive experiences.

Botpress supports custom LLM providers for its AI features.

## Prerequisites

- An LLM API account with an API key
- Botpress installed or accessible

## Setup

<Steps>
<Step>
### Get Your LLM API Key

1. Log in to your [LLM API dashboard](https://app.llmapi.ai/api-keys)
2. Click **Create Key to Start**
3. Copy your new API key immediately — it will only be shown once
4. Store the key securely (e.g., in a password manager or `.env` file)

<Callout type="info">
	LLM API is an OpenAI-compatible gateway that gives you access to dozens of AI
	models through a single API key and endpoint.
</Callout>

</Step>

<Step>
### Configure LLM API in Botpress

1. Open your Botpress Studio.
2. Navigate to Integration Settings → LLM.
3. Select "OpenAI" or "Custom" provider.
4. Enter:
   - **API Key**: paste the key you copied from app.llmapi.ai/api-keys
   - **Base URL**: https://api.llmapi.ai/v1
5. Select the model.
6. Click "Save".

</Step>

<Step>
### Test the Integration

Verify that Botpress can successfully communicate with LLM API by sending a test request. All requests will now be routed through LLM API.

</Step>
</Steps>

<Callout type="info">
	Botpress' AI features like knowledge answering and intent classification work
	with LLM API models.
</Callout>

## Benefits of Using LLM API with Botpress

- **Multi-Provider Access**: Use models from OpenAI, Anthropic, Google, and more through a single API
- **Cost Control**: Track and limit your AI spending with detailed usage analytics
- **Unified Billing**: One account for all providers instead of managing multiple API keys
- **Caching**: Reduce costs with response caching for repeated requests

<Callout type="info">
	View all available models on the [models page](https://llmapi.ai/models).
</Callout>
